{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /Users/phosseini/anaconda3/envs/corona/lib/python3.7/site-packages (0.5.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ØªÙ„Ú¯Ø±Ø§Ù… ØªÙˆÛŒÛŒØªØ± Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… ÙˆØ§ØªØ³ Ø¢Ù¾ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø² Ø§ÙˆÙ„ ğŸ˜ Ø§ÛŒÙ†Ù… Ø²Ù†Ø¯Ú¯ÛŒ Ù‚Ø±Ù†Ø·ÛŒÙ†Ù‡ Ø§ÛŒâ˜¹ï¸ ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø®Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨ Ú©Ø±ÙˆÙ†Ø§ Ùˆ ÛŒ Ù…Ø´Øª Ú†Ø±Øª Ùˆ Ù¾Ø±Øª Ø¯ÛŒÚ¯Ù‡ Ù†Ù‡ Ú©Ø³ÛŒ Ø­Ø§Ù„ØªÙˆ Ù…ÛŒÙ¾Ø±Ø³Ù‡ Ù† ÛŒ Ù¾ÛŒ Ø§Ù… Ø§Ø² Ú©Ø³ÛŒ Ú© Ù…Ù†ØªØ¸Ø±Ø´ÛŒ #Ù„Ø¹Ù†Øª_Ø¨Ù‡_Ú©Ø±ÙˆÙ†Ø§\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªÙ„Ú¯Ø±Ø§Ù… ØªÙˆÛŒÛŒØªØ± Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… ÙˆØ§ØªØ³ Ø¢Ù¾ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø² Ø§ÙˆÙ„ ğŸ˜ Ø§ÛŒÙ†Ù… Ø²Ù†Ø¯Ú¯ÛŒ Ù‚Ø±Ù†Ø·ÛŒÙ†Ù‡ Ø§ÛŒâ˜¹ï¸ ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø®Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨ Ú©Ø±ÙˆÙ†Ø§ Ùˆ ÛŒ Ù…Ø´Øª Ú†Ø±Øª Ùˆ Ù¾Ø±Øª Ø¯ÛŒÚ¯Ù‡ Ù†Ù‡ Ú©Ø³ÛŒ Ø­Ø§Ù„ØªÙˆ Ù…ÛŒÙ¾Ø±Ø³Ù‡ Ù† ÛŒ Ù¾ÛŒ Ø§Ù… Ø§Ø² Ú©Ø³ÛŒ Ú© Ù…Ù†ØªØ¸Ø±Ø´ÛŒ #Ù„Ø¹Ù†Øª_Ø¨Ù‡_Ú©Ø±ÙˆÙ†Ø§\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "def emoji_free_text(text):\n",
    "    return emoji.get_emoji_regexp().sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªÙ„Ú¯Ø±Ø§Ù… ØªÙˆÛŒÛŒØªØ± Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… ÙˆØ§ØªØ³ Ø¢Ù¾ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø² Ø§ÙˆÙ„  Ø§ÛŒÙ†Ù… Ø²Ù†Ø¯Ú¯ÛŒ Ù‚Ø±Ù†Ø·ÛŒÙ†Ù‡ Ø§ÛŒï¸ ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø®Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨ Ú©Ø±ÙˆÙ†Ø§ Ùˆ ÛŒ Ù…Ø´Øª Ú†Ø±Øª Ùˆ Ù¾Ø±Øª Ø¯ÛŒÚ¯Ù‡ Ù†Ù‡ Ú©Ø³ÛŒ Ø­Ø§Ù„ØªÙˆ Ù…ÛŒÙ¾Ø±Ø³Ù‡ Ù† ÛŒ Ù¾ÛŒ Ø§Ù… Ø§Ø² Ú©Ø³ÛŒ Ú© Ù…Ù†ØªØ¸Ø±Ø´ÛŒ #Ù„Ø¹Ù†Øª_Ø¨Ù‡_Ú©Ø±ÙˆÙ†Ø§\n"
     ]
    }
   ],
   "source": [
    "print(emoji_free_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "\n",
    "docs = [\"ØªÙˆØ³Ù„ Ø¨Ù‡ ØªØ¦ÙˆØ±ÛŒ #ØªÙˆÙ‡Ù…_ØªÙˆØ·Ø¦Ù‡ Ú†Ø´Ù…Ø§Ù†Ù…Ø§Ù† Ø±Ø§ Ø¨Ø± ÙˆØ§Ù‚Ø¹ÛŒØª Ù…ÛŒâ€ŒØ¨Ù†Ø¯Ø¯ Ùˆ Ø§Ø² Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø±Ø³Øª Ø¨Ø­Ø±Ø§Ù† Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ #Ú©Ø±ÙˆÙ†Ø§ #Ø¬Ù†Ú¯_Ø¨ÛŒÙˆÙ„Ú˜ÙˆÙ„ÛŒÚ©\"]\n",
    "\n",
    "\n",
    "def hazm_docs(docs):\n",
    "    normalizer = Normalizer()\n",
    "    stemmer = Stemmer()\n",
    "    lemmatizer = Lemmatizer()\n",
    "    processed_docs = []\n",
    "\n",
    "\n",
    "    for doc in docs:\n",
    "        normalized_doc = normalizer.normalize(doc)\n",
    "        doc_sents = sent_tokenize(normalized_doc)\n",
    "        words = []\n",
    "        for sent in doc_sents:\n",
    "            words.extend(word_tokenize(sent))\n",
    "\n",
    "        words_stem = [stemmer.stem(t) for t in words]\n",
    "        words_lemm = [lemmatizer.lemmatize(t) for t in words_stem]\n",
    "\n",
    "        processed_docs.append(\" \".join(words_lemm))\n",
    "    \n",
    "    return processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ØªÙˆØ³Ù„ Ø¨Ù‡ ØªØ¦ÙˆØ± #ØªÙˆÙ‡Ù…_ØªÙˆØ·Ø¦Ù‡ Ú†Ø´Ù…Ø§Ù† Ø±Ø§ Ø¨Ø± ÙˆØ§Ù‚Ø¹ Ø¨Ø³Øª#Ø¨Ù†Ø¯ Ùˆ Ø§Ø² Ù…Ø¯ÛŒØ± Ø¯Ø±Ø³ Ø¨Ø­Ø± Ø¬Ù„ÙˆÚ¯ÛŒØ± Ú©Ø±Ø¯#Ú©Ù† #Ú©Ø±ÙˆÙ†Ø§ #Ø¬Ù†Ú¯_Ø¨ÛŒÙˆÙ„Ú˜ÙˆÙ„ÛŒÚ©']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hazm_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ØªÙˆØ³Ù„',\n",
       " 'Ø¨Ù‡',\n",
       " 'ØªØ¦ÙˆØ±ÛŒ',\n",
       " '#ØªÙˆÙ‡Ù…_ØªÙˆØ·Ø¦Ù‡',\n",
       " 'Ú†Ø´Ù…Ø§Ù†Ù…Ø§Ù†',\n",
       " 'Ø±Ø§',\n",
       " 'Ø¨Ø±',\n",
       " 'ÙˆØ§Ù‚Ø¹ÛŒØª',\n",
       " 'Ù…ÛŒ\\u200cØ¨Ù†Ø¯Ø¯',\n",
       " 'Ùˆ',\n",
       " 'Ø§Ø²',\n",
       " 'Ù…Ø¯ÛŒØ±ÛŒØª',\n",
       " 'Ø¯Ø±Ø³Øª',\n",
       " 'Ø¨Ø­Ø±Ø§Ù†',\n",
       " 'Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ',\n",
       " 'Ù…ÛŒ\\u200cÚ©Ù†Ø¯',\n",
       " '#Ú©Ø±ÙˆÙ†Ø§',\n",
       " '#Ø¬Ù†Ú¯_Ø¨ÛŒÙˆÙ„Ú˜ÙˆÙ„ÛŒÚ©']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corona",
   "language": "python",
   "name": "corona"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
