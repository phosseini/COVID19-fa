{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "In this notebook, we show the preprocessing steps on tweets before doing any analysis (e.g. topic modeling.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# adding classes folder to system path\n",
    "sys.path.insert(0, os.path.abspath('..') + '/src')\n",
    "\n",
    "from pre_processing import PreProcessing\n",
    "from pre_processing import hazm_docs\n",
    "from pre_processing import emoji_free_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step [1]: Preprocessing raw `json`/`excel` files\n",
    "\n",
    "Tweets that we collect in real-time using the [Social Feed Manager (SFM) tool](https://gwu-libraries.github.io/sfm-ui/) can be downloaded as either `json` or `excel` files. These files should be placed in the following path: `data/input`.\n",
    "\n",
    "In the first step, we preprocess these json/excel files to create a cleaned tweet collection where we only keep a subset of fields for each tweet. Cleaned tweets will be put in the `data/cleaned` folder in excel (.xlsx) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `save_checkpoint` specifies the number of records in each cleaned excel file to avoid having very large files\n",
    "# WARNING: depending on how many files/tweets we have, running this cell can take a few hours\n",
    "PreProcessing().clean_data_json(save_checkpoint=150000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing preprocessing methods on Farsi text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ØªÙ„Ú¯Ø±Ø§Ù… ØªÙˆÛŒÛŒØªØ± Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… ÙˆØ§ØªØ³ Ø¢Ù¾ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø² Ø§ÙˆÙ„ ğŸ˜ Ø§ÛŒÙ†Ù… Ø²Ù†Ø¯Ú¯ÛŒ Ù‚Ø±Ù†Ø·ÛŒÙ†Ù‡ Ø§ÛŒâ˜¹ï¸ ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø®Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨ Ú©Ø±ÙˆÙ†Ø§ Ùˆ ÛŒ Ù…Ø´Øª Ú†Ø±Øª Ùˆ Ù¾Ø±Øª Ø¯ÛŒÚ¯Ù‡ Ù†Ù‡ Ú©Ø³ÛŒ Ø­Ø§Ù„ØªÙˆ Ù…ÛŒÙ¾Ø±Ø³Ù‡ Ù† ÛŒ Ù¾ÛŒ Ø§Ù… Ø§Ø² Ú©Ø³ÛŒ Ú© Ù…Ù†ØªØ¸Ø±Ø´ÛŒ #Ù„Ø¹Ù†Øª_Ø¨Ù‡_Ú©Ø±ÙˆÙ†Ø§\"\n",
    "docs = [\"ØªÙˆØ³Ù„ Ø¨Ù‡ ØªØ¦ÙˆØ±ÛŒ #ØªÙˆÙ‡Ù…_ØªÙˆØ·Ø¦Ù‡ Ú†Ø´Ù…Ø§Ù†Ù…Ø§Ù† Ø±Ø§ Ø¨Ø± ÙˆØ§Ù‚Ø¹ÛŒØª Ù…ÛŒâ€ŒØ¨Ù†Ø¯Ø¯ Ùˆ Ø§Ø² Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø±Ø³Øª Ø¨Ø­Ø±Ø§Ù† Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ #Ú©Ø±ÙˆÙ†Ø§ #Ø¬Ù†Ú¯_Ø¨ÛŒÙˆÙ„Ú˜ÙˆÙ„ÛŒÚ©\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ØªÙ„Ú¯Ø±Ø§Ù… ØªÙˆÛŒÛŒØªØ± Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… ÙˆØ§ØªØ³ Ø¢Ù¾ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø² Ø§ÙˆÙ„ ğŸ˜ Ø§ÛŒÙ†Ù… Ø²Ù†Ø¯Ú¯ÛŒ Ù‚Ø±Ù†Ø·ÛŒÙ†Ù‡ Ø§ÛŒâ˜¹ï¸ ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø®Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨ Ú©Ø±ÙˆÙ†Ø§ Ùˆ ÛŒ Ù…Ø´Øª Ú†Ø±Øª Ùˆ Ù¾Ø±Øª Ø¯ÛŒÚ¯Ù‡ Ù†Ù‡ Ú©Ø³ÛŒ Ø­Ø§Ù„ØªÙˆ Ù…ÛŒÙ¾Ø±Ø³Ù‡ Ù† ÛŒ Ù¾ÛŒ Ø§Ù… Ø§Ø² Ú©Ø³ÛŒ Ú© Ù…Ù†ØªØ¸Ø±Ø´ÛŒ #Ù„Ø¹Ù†Øª_Ø¨Ù‡_Ú©Ø±ÙˆÙ†Ø§\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ØªÙ„Ú¯Ø±Ø§Ù… ØªÙˆÛŒÛŒØªØ± Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… ÙˆØ§ØªØ³ Ø¢Ù¾ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø² Ø§ÙˆÙ„  Ø§ÛŒÙ†Ù… Ø²Ù†Ø¯Ú¯ÛŒ Ù‚Ø±Ù†Ø·ÛŒÙ†Ù‡ Ø§ÛŒï¸ ÙÙ‚Ø· Ùˆ ÙÙ‚Ø· Ø®Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨ Ú©Ø±ÙˆÙ†Ø§ Ùˆ ÛŒ Ù…Ø´Øª Ú†Ø±Øª Ùˆ Ù¾Ø±Øª Ø¯ÛŒÚ¯Ù‡ Ù†Ù‡ Ú©Ø³ÛŒ Ø­Ø§Ù„ØªÙˆ Ù…ÛŒÙ¾Ø±Ø³Ù‡ Ù† ÛŒ Ù¾ÛŒ Ø§Ù… Ø§Ø² Ú©Ø³ÛŒ Ú© Ù…Ù†ØªØ¸Ø±Ø´ÛŒ #Ù„Ø¹Ù†Øª_Ø¨Ù‡_Ú©Ø±ÙˆÙ†Ø§'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing emojis\n",
    "print(text) # before removing emojis\n",
    "emoji_free_text(text) # after removing emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing documents using hazm\n",
    "docs = hazm_docs(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ØªÙˆØ³Ù„ Ø¨Ù‡ ØªØ¦ÙˆØ±ÛŒ #ØªÙˆÙ‡Ù…_ØªÙˆØ·Ø¦Ù‡ Ú†Ø´Ù…Ø§Ù†Ù…Ø§Ù† Ø±Ø§ Ø¨Ø± ÙˆØ§Ù‚Ø¹ÛŒØª Ù…ÛŒ\\u200cØ¨Ù†Ø¯Ø¯ Ùˆ Ø§Ø² Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø±Ø³Øª Ø¨Ø­Ø±Ø§Ù† Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒ\\u200cÚ©Ù†Ø¯ #Ú©Ø±ÙˆÙ†Ø§ #Ø¬Ù†Ú¯_Ø¨ÛŒÙˆÙ„Ú˜ÙˆÙ„ÛŒÚ©'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corona",
   "language": "python",
   "name": "corona"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
